---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<span class='anchor' id='about-me'></span>

I am a third-year undergraduate student majoring in Information and Computing Science at the School of Mathematics and Statistics, Wuhan University of Technology. My research interests primarily focus on **spatio-temporal sequence modeling**, **inference acceleration for large-scale models**, and **efficient attention mechanisms**.

In terms of research, I joined a time series research group in the second semester of my sophomore year, where I have been working on the design of efficient spatiotemporal forecasting architectures. During this period, I proposed LOSTFormer as the first author, a linear spatio-temporal Transformer with learnable orthogonal rotation attention, which significantly enhances model representational capacity while preserving theoretical consistency and linear computational complexity. The corresponding paper is currently under review.

At present, my research focus has expanded to applications of Learning to Hash, and I aspire to pursue further research in **ML systems (MLSys)** and **large language models (LLMs)**. In terms of engineering and competitive programming, I have received multiple awards in ICPC, CCPC, CCF-CSP, and other national-level programming competitions, demonstrating strong proficiency in algorithm design and system-level implementation.

I am passionate about advancing my understanding of Machine Learning and aspire to make meaningful contributions to the field in the
future. Please feel free to contact me if youâ€™d like to discuss related research areas.ğŸ˜„

<br>

# ğŸ”¬ Research Skills

- ğŸ’ª **Strongly self-motivated and passionate about research:** My experience includes systematic replication and improvement of deep learning models, as well as practical deployment and fine-tuning of large language models, bridging theoretical understanding with empirical validation.


- ğŸ’» **Excellent algorithm design and code implementation capabilities:** I won **bronze medals** at the ICPC 2024 Regionals
  and currently have a Codeforces Rating of [<span style="color: blue;">**1777**</span>](https://codeforces.com/profile/TheEndd). In addition, I have fully implemented the entire workflow for small-scale language models, **from pre-training to SFT**, enabling them to conduct conversations of a certain quality. Further details can be found in the Projection section of this paper.


- ğŸ“ **Theoretical derivation capability:** In the course of exploring efficient attention mechanisms, I conducted theoretical analyses and derivations related to **Performer**. To better align with my subsequent research directions, I also carried out theoretical derivations of several hashing methods, including **Spectral Hashing**, **Locality-Sensitive Hashing (LSH)**, and **Asymmetric Deep Supervised Hashing (ADSH)**.

<br>

# ğŸ“… News

- [2025.11] I won a bronze medal at the ICPC Wuhan Regionals.

- [2025.10] I won a bronze medal at the ICPC Chengdu Regionals.

- [2025.03] I started working on time series forecasting architecture under the guidance of
  Prof. [Liang Xie](http://ssci.whut.edu.cn/szdw/zrjs/202309/t20230921_939468.shtml).

- [2024.12] I won a bronze medal at the ICPC Hong Kong Regionals.

- [2024.11] I won a bronze medal at the CCPC Zhengzhou Regionals.

<br>

# ğŸ† Honors & Awards

## Programming Competitions

- **ICPC\CCPC International Collegiate Programming Contest** \
ğŸ¥‰ Regional Bronze Medalist (Hong Kong, Chengdu, Wuhan, Zhengzhou) \
Demonstrated strong problem-solving skills in algorithms and data structures, with a particular focus on graph theory and advanced data structures.


- **Group Programming Ladder Tournament (GPLT)** \
ğŸ¥ˆ Individual Second Prize \
ğŸ¥ˆ Team Second Prize (Ranked 1st within the team)


- **CCF Certified Software Professional (CSP)** \
ğŸ”¹ Score: 300 \
Ranked in the Top 3% nationwide (40th CCF CSP examination).


- **RAICOM Robotics Development Competition 2025** \
ğŸ¥‡ National Final â€“ Programming Skills Track \
Achieved **full score**, demonstrating excellence in algorithmic implementation and engineering robustness.


- **Codeforces** \
ğŸ”¹ Max Rating: [<span style="color: blue;">**1777**</span>](https://codeforces.com/profile/TheEndd) \
Specialized in graph algorithms, data structures, and competitive programming optimization. \
ğŸ‘‰ Contest template: [GitHub Repository](https://github.com/QAQYYC/ACM-Template)

## Honors & Scholarships
- **National Scholarship (China)** Ã—1
- **Merit Student of Wuhan University of Technology** Ã—1

<br>

# ğŸ’» Projections

## MiniMind (LLM Built from Scratch)

- ğŸ‘‰**Model Architecture:** Developed a **LLaMA-like** language model from scratch using **PyTorch**, implementing core architectural components including **RoPE** (Rotary Positional Embeddings), **RMSNorm**, and **SwiGLU** activation functions.

- ğŸ‘‰**Training Pipeline:** Engineered an end-to-end training pipeline encompassing both **Pretraining** on raw text and **Supervised Fine-Tuning (Full SFT)** for instruction following.

- ğŸ‘‰**Inference Optimization:** Deployed a text generation script featuring **KV Cache** optimization for reduced latency and integrated **Top-p/Temperature** sampling for diverse, streaming responses.


